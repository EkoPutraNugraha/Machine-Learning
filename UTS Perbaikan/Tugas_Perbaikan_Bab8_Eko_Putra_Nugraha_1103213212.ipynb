{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzuTEkq8s3co"
      },
      "outputs": [],
      "source": [
        "# Import pustaka\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Memuat dataset Iris\n",
        "print(\"=== Memuat Dataset Iris ===\")\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris.data, iris.target, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Dimensi data latih:\", X_train.shape)\n",
        "print(\"Dimensi data uji:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbHbbjIEtEmm",
        "outputId": "58be1600-793c-4eeb-a5a6-65b51fb44329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Memuat Dataset Iris ===\n",
            "Dimensi data latih: (105, 4)\n",
            "Dimensi data uji: (45, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode ini menunjukkan proses pembagian dataset Iris menggunakan fungsi train_test_split dari library Scikit-learn. Dataset Iris merupakan dataset yang sering digunakan untuk pembelajaran mesin, dengan total 150 sampel data yang memiliki 4 fitur (sepal length, sepal width, petal length, petal width) dan 3 kelas target (setosa, versicolor, virginica). Pada kode ini, dataset dibagi menjadi data latih (X_train dan y_train) yang digunakan untuk melatih model, dan data uji (X_test dan y_test) yang digunakan untuk mengevaluasi performa model. Proporsi pembagian data diatur dengan test_size=0.3, artinya 30% data digunakan sebagai data uji, sementara 70% sisanya menjadi data latih.\n",
        "\n",
        "Hasil output menunjukkan bahwa data latih memiliki dimensi (105, 4), yang berarti 105 sampel dengan 4 fitur masing-masing, sedangkan data uji memiliki dimensi (45, 4) untuk 45 sampel dengan 4 fitur. Dengan pembagian ini, data uji tetap cukup besar untuk mengevaluasi model secara akurat, sementara data latih memiliki cukup banyak sampel untuk melatih model agar dapat mengenali pola dengan baik. Penggunaan parameter random_state=42 memastikan bahwa pembagian data dilakukan secara acak tetapi dapat direplikasi untuk hasil yang konsisten. Hal ini penting dalam eksperimen pembelajaran mesin agar hasil analisis tetap stabil dan dapat dibandingkan."
      ],
      "metadata": {
        "id": "PNcdj_9c6P6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Melatih Model Random Forest\n",
        "print(\"\\n=== Melatih Model Random Forest ===\")\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluasi model\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUAwLx6kw17U",
        "outputId": "e92177a5-2757-40a4-b049-2f6e17f5390a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Melatih Model Random Forest ===\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algoritma Random Forest digunakan untuk melatih model klasifikasi pada dataset Iris. Random Forest adalah metode ensemble yang menggabungkan beberapa pohon keputusan (decision trees) untuk membuat prediksi yang lebih akurat dan robust. Pada kode ini, model dilatih dengan parameter n_estimators=100, yang berarti 100 pohon keputusan digunakan dalam ensemble, dan random_state=42 untuk memastikan hasil yang konsisten. Setelah model dilatih menggunakan data latih (X_train dan y_train), prediksi dilakukan pada data uji (X_test).\n",
        "\n",
        "Hasil evaluasi model menunjukkan performa yang sempurna dengan nilai precision, recall, dan f1-score sebesar 1.00 untuk semua kelas (0, 1, dan 2). Hal ini berarti model berhasil memprediksi semua sampel dalam data uji dengan benar tanpa ada kesalahan. Akurasi keseluruhan juga mencapai 100% pada data uji yang terdiri dari 45 sampel. Meskipun hasil ini mengindikasikan bahwa model sangat baik untuk dataset ini, performa sempurna seperti ini perlu ditinjau dengan hati-hati, karena bisa jadi ini akibat kompleksitas dataset yang rendah atau ukuran dataset yang kecil. Untuk aplikasi dunia nyata, hasil seperti ini jarang terjadi karena data biasanya lebih kompleks dan mengandung lebih banyak noise."
      ],
      "metadata": {
        "id": "P356NAyU6cnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Menyimpan Model ke File\n",
        "print(\"\\n=== Menyimpan Model ===\")\n",
        "joblib.dump(rf, \"random_forest_model.pkl\")\n",
        "print(\"Model disimpan sebagai 'random_forest_model.pkl'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YNcjiKSxBKL",
        "outputId": "2875670a-1d75-4c00-ad31-6868fc4d5c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Menyimpan Model ===\n",
            "Model disimpan sebagai 'random_forest_model.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Random Forest yang telah dilatih disimpan ke dalam file menggunakan library joblib. Metode joblib.dump() digunakan untuk menyimpan objek model rf ke file dengan nama random_forest_model.pkl. Format file .pkl adalah format pickle yang memungkinkan penyimpanan objek Python sehingga dapat diakses kembali di masa depan tanpa perlu melatih ulang model. Hal ini sangat berguna untuk efisiensi waktu, terutama pada model yang membutuhkan proses pelatihan yang lama.\n",
        "\n",
        "Output dari kode ini menunjukkan bahwa model berhasil disimpan dengan nama file random_forest_model.pkl. Penyimpanan model ke file mempermudah distribusi dan penggunaan ulang model dalam aplikasi dunia nyata, seperti implementasi prediksi berbasis web atau integrasi ke dalam sistem produksi. Model yang disimpan dapat dimuat kembali menggunakan joblib.load() kapan saja, memungkinkan pengguna untuk melanjutkan pekerjaan atau langsung melakukan prediksi tanpa harus melalui proses pelatihan model dari awal. Teknik ini merupakan praktik yang umum dalam pengembangan dan deployment model pembelajaran mesin."
      ],
      "metadata": {
        "id": "oCj6vbuy6kNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Memuat Model dari File\n",
        "print(\"\\n=== Memuat Model ===\")\n",
        "loaded_rf = joblib.load(\"random_forest_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHM4eqvcxEc1",
        "outputId": "f95fb2e2-23b7-44fb-9e40-038855724f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Memuat Model ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada potongan kode ini, model Random Forest yang sebelumnya telah disimpan ke dalam file dengan nama random_forest_model.pkl dimuat kembali menggunakan fungsi joblib.load(). Dengan memuat model yang telah disimpan, pengguna dapat langsung menggunakan model tersebut untuk berbagai keperluan, seperti melakukan prediksi tanpa perlu melatih ulang model dari awal. Hal ini sangat efisien terutama untuk model yang membutuhkan waktu pelatihan yang lama atau yang diterapkan dalam lingkungan produksi.\n",
        "\n",
        "Output dari kode ini menunjukkan bahwa proses pemuatan model berhasil, meskipun tidak ada output eksplisit yang dihasilkan selain pesan konfirmasi \"Memuat Model\". Model yang dimuat kembali ini (loaded_rf) memiliki semua atribut dan parameter yang sama seperti saat model disimpan, sehingga siap digunakan seperti model yang dilatih langsung. Teknik ini memungkinkan fleksibilitas dan penghematan waktu dalam pengembangan dan deployment model pembelajaran mesin, karena model dapat dibagi, digunakan ulang, atau diintegrasikan ke aplikasi lain dengan mudah."
      ],
      "metadata": {
        "id": "ACuCxhLp6rba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluasi model yang dimuat\n",
        "y_pred_loaded = loaded_rf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred_loaded)\n",
        "print(\"Akurasi Model yang Dimuat: {:.2f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZZSewGxxFCA",
        "outputId": "4fe7a748-6c95-4dcc-ab74-1569286c1ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi Model yang Dimuat: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Random Forest yang sebelumnya dimuat dari file (loaded_rf) diuji ulang dengan menggunakan data uji (X_test) untuk memastikan model yang dimuat tetap berfungsi sebagaimana mestinya. Prediksi dilakukan dengan metode predict, dan akurasi model dihitung menggunakan fungsi accuracy_score dari Scikit-learn dengan membandingkan hasil prediksi (y_pred_loaded) terhadap label aktual data uji (y_test). Hasil akurasi kemudian ditampilkan dengan format dua angka desimal.\n",
        "\n",
        "Output menunjukkan bahwa akurasi model yang dimuat adalah 1.00 (100%), yang sama dengan akurasi saat model awalnya diuji setelah pelatihan. Hal ini menunjukkan bahwa proses penyimpanan dan pemuatan model tidak mengubah performa model. Kemampuan untuk memuat model tanpa kehilangan akurasi sangat penting, terutama dalam aplikasi dunia nyata, karena memungkinkan pengembang untuk menyimpan model yang sudah optimal dan menggunakannya kembali tanpa memerlukan pelatihan ulang. Teknik ini juga memastikan efisiensi dalam pipeline pembelajaran mesin, terutama untuk model dengan proses pelatihan yang mahal dalam hal waktu atau sumber daya."
      ],
      "metadata": {
        "id": "wAxLCI946xGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Menggunakan Model untuk Prediksi Baru\n",
        "print(\"\\n=== Prediksi dengan Model ===\")\n",
        "new_data = np.array([[5.1, 3.5, 1.4, 0.2],  # Contoh 1: Setosa\n",
        "                     [6.7, 3.1, 4.7, 1.5],  # Contoh 2: Versicolor\n",
        "                     [7.2, 3.6, 6.1, 2.5]])  # Contoh 3: Virginica\n",
        "\n",
        "predictions = loaded_rf.predict(new_data)\n",
        "predicted_classes = [iris.target_names[p] for p in predictions]\n",
        "\n",
        "print(\"Data Baru:\")\n",
        "print(new_data)\n",
        "print(\"Prediksi:\")\n",
        "print(predicted_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_i0GjPzxH-5",
        "outputId": "1b5f89e3-2621-488d-d01d-bf2b670fc4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Prediksi dengan Model ===\n",
            "Data Baru:\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [7.2 3.6 6.1 2.5]]\n",
            "Prediksi:\n",
            "['setosa', 'versicolor', 'virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Kode ini menggunakan model Random Forest yang telah dimuat sebelumnya untuk melakukan prediksi pada data baru. Data baru (new_data) terdiri dari tiga sampel dengan fitur-fitur yang mencerminkan panjang dan lebar kelopak (sepal) serta panjang dan lebar mahkota bunga (petal). Setiap sampel direpresentasikan sebagai array numerik yang berisi empat fitur. Model memprediksi kelas target untuk masing-masing sampel, kemudian hasil prediksi diterjemahkan ke dalam nama spesies bunga yang sesuai dengan dataset Iris (setosa, versicolor, virginica).\n",
        "\n",
        "Hasil output menunjukkan bahwa model berhasil memprediksi spesies bunga dengan benar berdasarkan data baru. Untuk sampel pertama, model memprediksi setosa, untuk sampel kedua versicolor, dan untuk sampel ketiga virginica. Hal ini menunjukkan bahwa model yang telah dimuat tetap bekerja dengan baik dalam memprediksi data baru, konsisten dengan performa model saat diuji sebelumnya. Ini mencerminkan keandalan model Random Forest dalam mengenali pola pada dataset Iris, bahkan untuk data yang belum pernah dilihat sebelumnya. Teknik ini relevan untuk aplikasi dunia nyata, seperti sistem klasifikasi otomatis berdasarkan data masukan baru."
      ],
      "metadata": {
        "id": "RW3GUE2V62CR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Eksperimen: Menyimpan dan Memuat dengan Versi yang Berbeda\n",
        "print(\"\\n=== Eksperimen: Simpan dan Muat Model dengan Versi Berbeda ===\")\n",
        "# Simpan model dalam format kompresi\n",
        "joblib.dump(rf, \"random_forest_model_compressed.pkl\", compress=3)\n",
        "print(\"Model disimpan dengan kompresi sebagai 'random_forest_model_compressed.pkl'\")\n",
        "\n",
        "# Memuat model yang dikompresi\n",
        "loaded_rf_compressed = joblib.load(\"random_forest_model_compressed.pkl\")\n",
        "\n",
        "# Evaluasi model yang dikompresi\n",
        "y_pred_compressed = loaded_rf_compressed.predict(X_test)\n",
        "accuracy_compressed = accuracy_score(y_test, y_pred_compressed)\n",
        "print(\"Akurasi Model yang Dimuat (dengan kompresi): {:.2f}\".format(accuracy_compressed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I57Tj_DKxKJF",
        "outputId": "a74acd64-d741-401e-ddac-f6299486f621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Eksperimen: Simpan dan Muat Model dengan Versi Berbeda ===\n",
            "Model disimpan dengan kompresi sebagai 'random_forest_model_compressed.pkl'\n",
            "Akurasi Model yang Dimuat (dengan kompresi): 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode ini menunjukkan eksperimen penyimpanan model Random Forest dalam format terkompresi menggunakan library joblib. Model disimpan dengan nama file random_forest_model_compressed.pkl dan menggunakan parameter compress=3, yang memungkinkan file model dikompresi untuk mengurangi ukuran file. Kompresi ini berguna ketika model perlu disimpan atau dikirimkan dalam lingkungan dengan keterbatasan penyimpanan atau bandwidth, seperti deployment di sistem berbasis cloud. Setelah disimpan, model yang terkompresi dimuat kembali menggunakan fungsi joblib.load(), dan evaluasi dilakukan untuk memastikan performa model tetap sama.\n",
        "\n",
        "Hasil evaluasi menunjukkan bahwa model yang disimpan dalam format terkompresi tetap memberikan akurasi 1.00 (100%) saat diuji dengan data uji. Ini menunjukkan bahwa kompresi tidak memengaruhi performa model dan hanya berdampak pada ukuran file. Proses ini sangat relevan dalam pengembangan dan deployment pembelajaran mesin karena memungkinkan efisiensi penyimpanan tanpa mengorbankan kualitas model. Eksperimen ini menegaskan fleksibilitas penggunaan joblib untuk berbagai kebutuhan penyimpanan model dengan opsi penghematan ruang penyimpanan."
      ],
      "metadata": {
        "id": "I9OpNltz629w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Simpan Model dengan Metadata (Custom Object)\n",
        "print(\"\\n=== Menyimpan Model dengan Metadata ===\")\n",
        "metadata = {\n",
        "    \"model\": rf,\n",
        "    \"description\": \"Random Forest model untuk dataset Iris\",\n",
        "    \"version\": \"1.0\",\n",
        "    \"date\": \"2025-01-02\"\n",
        "}\n",
        "\n",
        "# Simpan objek metadata\n",
        "joblib.dump(metadata, \"model_with_metadata.pkl\")\n",
        "print(\"Model dengan metadata disimpan sebagai 'model_with_metadata.pkl'\")\n",
        "\n",
        "# Muat model dengan metadata\n",
        "loaded_metadata = joblib.load(\"model_with_metadata.pkl\")\n",
        "print(\"\\nDeskripsi Model:\")\n",
        "print(loaded_metadata[\"description\"])\n",
        "print(\"Versi:\", loaded_metadata[\"version\"])\n",
        "print(\"Tanggal:\", loaded_metadata[\"date\"])\n",
        "\n",
        "# Gunakan model dari metadata\n",
        "loaded_model_from_metadata = loaded_metadata[\"model\"]\n",
        "y_pred_metadata = loaded_model_from_metadata.predict(X_test)\n",
        "accuracy_metadata = accuracy_score(y_test, y_pred_metadata)\n",
        "print(\"Akurasi Model dari Metadata: {:.2f}\".format(accuracy_metadata))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuCONxO5xL9r",
        "outputId": "58a68e3d-64ab-4a24-c6b9-5d1bbd1f0955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Menyimpan Model dengan Metadata ===\n",
            "Model dengan metadata disimpan sebagai 'model_with_metadata.pkl'\n",
            "\n",
            "Deskripsi Model:\n",
            "Random Forest model untuk dataset Iris\n",
            "Versi: 1.0\n",
            "Tanggal: 2025-01-02\n",
            "Akurasi Model dari Metadata: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Random Forest disimpan bersama dengan metadata tambahan dalam satu objek menggunakan joblib. Metadata ini berisi informasi tambahan seperti deskripsi model, versi, dan tanggal, yang membantu mendokumentasikan model untuk referensi di masa depan. Metadata dan model disimpan dalam file model_with_metadata.pkl. Teknik ini berguna untuk melacak informasi penting mengenai model, seperti konteks penggunaannya, versi yang digunakan, dan waktu pembuatan, yang sangat membantu dalam manajemen model pada proyek besar.\n",
        "\n",
        "Output menunjukkan bahwa file berhasil disimpan dan metadata berhasil dimuat kembali. Metadata yang dimuat menampilkan informasi seperti deskripsi (\"Random Forest model untuk dataset Iris\"), versi (\"1.0\"), dan tanggal (\"2025-01-02\"). Selain itu, model yang disimpan di dalam metadata diuji kembali menggunakan data uji, dan hasil akurasi tetap 1.00 (100%), menunjukkan bahwa proses penyimpanan dengan metadata tidak memengaruhi performa model. Pendekatan ini memastikan dokumentasi model yang lengkap dan tetap menjaga keandalannya untuk digunakan dalam aplikasi selanjutnya. Teknik ini sangat relevan untuk lingkungan kolaboratif atau produksi, di mana pengelolaan model yang terorganisasi sangat penting."
      ],
      "metadata": {
        "id": "CXbqftBw7DVV"
      }
    }
  ]
}